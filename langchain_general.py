# -*- coding: utf-8 -*-
"""langchain_general.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fg4MBYgxYumYaAgeQqcgNJK0-DihBIvS

This code sample was presented on DataArt Summer School Workshop: "How to build simple ChatGPT prototypes with UI" on July 21 2023. This sample was used for demonstration only but can be reused freely to any needs.

# Dependency installation
"""




# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive

"""# Import libraries

"""

import nltk
import os
import streamlit as st
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain import OpenAI, VectorDBQA
from langchain.document_loaders import DirectoryLoader
nltk.download('averaged_perceptron_tagger')

"""# Load credentials

# Create document loader
"""
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

def create_loader():
    loader = DirectoryLoader('essays/', glob='*.txt')
    return loader

"""# Create document spliter"""

def split_documents():
    loader = create_loader()
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)
    texts = text_splitter.split_documents(documents)
    return texts

"""# Vector DBQA"""

def vectordbqa(query: str):
    embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])
    texts = split_documents()
    docsearch = Chroma.from_documents(texts, embeddings)
    opena_ai_llm = OpenAI() # add params
    qa = VectorDBQA.from_chain_type(llm=opena_ai_llm, chain_type="stuff", vectorstore=docsearch, return_source_documents=True)

    result = qa({"query": query})
    return result